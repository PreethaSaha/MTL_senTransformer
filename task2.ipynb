{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: It's sunny today.\n",
      "Predicted Topic (Task A): 1 | Predicted Sentiment (Task B): 0\n",
      "Embedding preview: [ 0.0066951  -0.02386935  0.00145519  0.00737709  0.0201737 ] ...\n",
      "\n",
      "Sentence: This laptop has great battery life.\n",
      "Predicted Topic (Task A): 2 | Predicted Sentiment (Task B): 0\n",
      "Embedding preview: [-0.00542451 -0.02068131  0.02674492  0.01063831  0.03491297] ...\n",
      "\n",
      "Sentence: The football match was disappointing.\n",
      "Predicted Topic (Task A): 1 | Predicted Sentiment (Task B): 1\n",
      "Embedding preview: [-0.00851533 -0.03751256 -0.02684303  0.0094255  -0.02344177] ...\n",
      "\n",
      "Sentence: AI is revolutionizing healthcare and finance.\n",
      "Predicted Topic (Task A): 2 | Predicted Sentiment (Task B): 1\n",
      "Embedding preview: [ 0.00240536 -0.00465826  0.0050031   0.0310524   0.03569923] ...\n",
      "\n",
      "Sentence: Rain dampened the final leg of the cycling tournament.\n",
      "Predicted Topic (Task A): 1 | Predicted Sentiment (Task B): 1\n",
      "Embedding preview: [-0.01912113 -0.03690866  0.01899971  0.00336774  0.01271178] ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiTaskSentenceTransformer(nn.Module):\n",
    "    def __init__(self, model_name='distilbert-base-uncased', num_labels_task_a=3, num_labels_task_b=2):\n",
    "        super(MultiTaskSentenceTransformer, self).__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.pooling = 'mean'\n",
    "\n",
    "        self.classifier_task_a = nn.Linear(hidden_size, num_labels_task_a)  # Task A: sentence classification\n",
    "        self.classifier_task_b = nn.Linear(hidden_size, num_labels_task_b)  # Task B: sentiment analysis\n",
    "\n",
    "    def mean_pooling(self, outputs, attention_mask):\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        return sum_embeddings / torch.clamp(sum_mask, min=1e-9)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "        outputs = self.encoder(**inputs)\n",
    "        sentence_embeddings = self.mean_pooling(outputs, inputs['attention_mask'])\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "        logits_task_a = self.classifier_task_a(sentence_embeddings)\n",
    "        logits_task_b = self.classifier_task_b(sentence_embeddings)\n",
    "\n",
    "        return logits_task_a, logits_task_b, sentence_embeddings\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Instantiate model\n",
    "    model = MultiTaskSentenceTransformer()\n",
    "    model.eval()\n",
    "\n",
    "    # Sample sentences \n",
    "    sentences = [\n",
    "        \"It's sunny today.\",                                      # Task A: Weather, Task B: Positive\n",
    "        \"This laptop has great battery life.\",                    # Task A: Technology, Task B: Positive\n",
    "        \"The football match was disappointing.\",                  # Task A: Sports, Task B: Negative\n",
    "        \"AI is revolutionizing healthcare and finance.\",          # Task A: Technology, Task B: Positive\n",
    "        \"Rain dampened the final leg of the cycling tournament.\"  # Task A: Sports, Task B: Negative\n",
    "    ]\n",
    "\n",
    "    # Label reference (for testing later)\n",
    "    # Task A (sentence classification): 0 = Technology, 1 = Weather, 2 = Sports\n",
    "    # Task B (sentiment): 0 = Negative, 1 = Positive\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        logits_a, logits_b, embeddings = model(sentences)\n",
    "        preds_a = torch.argmax(logits_a, dim=1)\n",
    "        preds_b = torch.argmax(logits_b, dim=1)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        print(f\"\\nSentence: {sentence}\")\n",
    "        print(f\"Predicted Topic (Task A): {preds_a[i].item()} | Predicted Sentiment (Task B): {preds_b[i].item()}\")\n",
    "        print(f\"Embedding preview: {embeddings[i][:5].numpy()} ...\")  # First 5 dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mangesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
