{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbimporter\n",
      "  Downloading nbimporter-0.3.4-py3-none-any.whl.metadata (252 bytes)\n",
      "Downloading nbimporter-0.3.4-py3-none-any.whl (4.9 kB)\n",
      "Installing collected packages: nbimporter\n",
      "Successfully installed nbimporter-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Loss = 1.7964, Task A Accuracy = 0.40, Task B Accuracy = 0.40\n",
      "\n",
      "Detailed predictions per sentence:\n",
      "\n",
      "Sentence: \"AI is reshaping industries.\"\n",
      "  Predicted Topic    : Weather | True Topic    : Tech\n",
      "  Predicted Sentiment: Positive  | True Sentiment: Positive\n",
      "\n",
      "Sentence: \"The game ended in a draw.\"\n",
      "  Predicted Topic    : Weather | True Topic    : Sports\n",
      "  Predicted Sentiment: Positive  | True Sentiment: Negative\n",
      "\n",
      "Sentence: \"It rained heavily last night.\"\n",
      "  Predicted Topic    : Weather | True Topic    : Weather\n",
      "  Predicted Sentiment: Positive  | True Sentiment: Negative\n",
      "\n",
      "Sentence: \"This new phone is amazing.\"\n",
      "  Predicted Topic    : Weather | True Topic    : Tech\n",
      "  Predicted Sentiment: Positive  | True Sentiment: Positive\n",
      "\n",
      "Sentence: \"The forecast predicts thunderstorms.\"\n",
      "  Predicted Topic    : Weather | True Topic    : Weather\n",
      "  Predicted Sentiment: Positive  | True Sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nbimporter\n",
    "from task2 import MultiTaskSentenceTransformer\n",
    "\n",
    "# Hypothetical Data (for illustration only)\n",
    "sample_sentences = [\n",
    "    \"AI is reshaping industries.\",        # Tech, Positive\n",
    "    \"The game ended in a draw.\",          # Sports, Negative\n",
    "    \"It rained heavily last night.\",      # Weather, Negative\n",
    "    \"This new phone is amazing.\",         # Tech, Positive\n",
    "    \"The forecast predicts thunderstorms.\" # Weather, Negative\n",
    "]\n",
    "\n",
    "# Labels: Task A = Topic, Task B = Sentiment\n",
    "labels_a = torch.tensor([0, 1, 2, 0, 2])  # 0=Tech, 1=Sports, 2=Weather\n",
    "labels_b = torch.tensor([1, 0, 0, 1, 0])  # 0=Negative, 1=Positive\n",
    "\n",
    "# Class name mappings\n",
    "topic_map = {0: \"Tech\", 1: \"Sports\", 2: \"Weather\"}\n",
    "sentiment_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "\n",
    "# Model & Optimizer\n",
    "model = MultiTaskSentenceTransformer()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop (1 epoch only for illustration)\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits_a, logits_b, _ = model(sample_sentences)\n",
    "\n",
    "    loss_a = loss_fn(logits_a, labels_a)\n",
    "    loss_b = loss_fn(logits_b, labels_b)\n",
    "\n",
    "    total_loss = loss_a + loss_b\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Predictions\n",
    "    preds_a = torch.argmax(logits_a, dim=1)\n",
    "    preds_b = torch.argmax(logits_b, dim=1)\n",
    "\n",
    "    acc_a = (preds_a == labels_a).float().mean().item()\n",
    "    acc_b = (preds_b == labels_b).float().mean().item()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    print(f\"Loss = {total_loss.item():.4f}, Task A Accuracy = {acc_a:.2f}, Task B Accuracy = {acc_b:.2f}\\n\")\n",
    "\n",
    "    print(\"Detailed predictions per sentence:\\n\")\n",
    "    for i, sentence in enumerate(sample_sentences):\n",
    "        pred_topic = topic_map[preds_a[i].item()]\n",
    "        true_topic = topic_map[labels_a[i].item()]\n",
    "        pred_sent = sentiment_map[preds_b[i].item()]\n",
    "        true_sent = sentiment_map[labels_b[i].item()]\n",
    "\n",
    "        print(f\"Sentence: \\\"{sentence}\\\"\")\n",
    "        print(f\"  Predicted Topic    : {pred_topic} | True Topic    : {true_topic}\")\n",
    "        print(f\"  Predicted Sentiment: {pred_sent}  | True Sentiment: {true_sent}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mangesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
